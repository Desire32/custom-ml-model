{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbUE6X/J5Bq2Pfl4ywHAhU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpi7YR-CfLDr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llama\n",
        "llama = \"openlm-research/open_llama_3b\"\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\n",
        "    llama,\n",
        "    torch_dtype=torch.float16, ## gpu support\n",
        "    device_map=\"auto\",\n",
        "    )\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(llama)"
      ],
      "metadata": {
        "id": "12wW7Luh3y10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# falcon\n",
        "falcon = \"tiiuae/falcon-rw-1b\"\n",
        "falcon_model = AutoModelForCausalLM.from_pretrained(\n",
        "    falcon,\n",
        "    torch_dtype=torch.float16, ## gpu support\n",
        "    device_map=\"auto\",\n",
        "    )\n",
        "falcon_tokenizer = AutoTokenizer.from_pretrained(falcon)"
      ],
      "metadata": {
        "id": "q4wMJayl1_7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qwen\n",
        "!pip install transformers_stream_generator\n",
        "!pip install hf_xet # http stuff\n",
        "!pip install tiktoken\n",
        "qwen = \"Qwen/Qwen-1_8B-Chat\"\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "    qwen,\n",
        "    torch_dtype=torch.float16, ## gpu support\n",
        "    device_map=\"auto\",\n",
        "    )\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen)"
      ],
      "metadata": {
        "id": "cYnf4y9u2lAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deepseek\n",
        "deepseek = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
        "deepseek_model = AutoModelForCausalLM.from_pretrained(\n",
        "    deepseek,\n",
        "    torch_dtype=torch.float16, ## gpu support\n",
        "    device_map=\"auto\",\n",
        "    )\n",
        "deepseek_tokenizer = AutoTokenizer.from_pretrained(deepseek)"
      ],
      "metadata": {
        "id": "nH4flTl53kYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M1KJ2ZZxt2xg"
      }
    }
  ]
}