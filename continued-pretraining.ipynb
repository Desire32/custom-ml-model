{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11797985,"sourceType":"datasetVersion","datasetId":7408757}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nimport torch\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_KEY\")\n\nfrom huggingface_hub import login\n\nlogin(token=secret_value_0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:35:48.167274Z","iopub.execute_input":"2025-05-13T20:35:48.167556Z","iopub.status.idle":"2025-05-13T20:36:07.750071Z","shell.execute_reply.started":"2025-05-13T20:35:48.167532Z","shell.execute_reply":"2025-05-13T20:36:07.749431Z"}},"outputs":[{"name":"stderr","text":"2025-05-13 20:36:00.115146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747168560.314634     474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747168560.370077     474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import nltk # to convert text into some more presentable way\nnltk.download(\"punkt\")\nnltk.download('punkt_tab')\nfrom nltk.tokenize import sent_tokenize, word_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:36:07.751285Z","iopub.execute_input":"2025-05-13T20:36:07.751909Z","iopub.status.idle":"2025-05-13T20:36:08.424379Z","shell.execute_reply.started":"2025-05-13T20:36:07.751886Z","shell.execute_reply":"2025-05-13T20:36:08.423631Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"file_name = \"/kaggle/input/church-s/church_text\"\nwith open(file_name, \"r\", encoding=\"utf-8\") as file: ## reading a file and storing it into one variable\n    f = file.read()\n    sentenses = sent_tokenize(f) # our english teacher\ntokenized_sentenses = [word_tokenize(sent) for sent in sentenses] # structure a text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:36:08.425137Z","iopub.execute_input":"2025-05-13T20:36:08.425329Z","iopub.status.idle":"2025-05-13T20:36:08.473881Z","shell.execute_reply.started":"2025-05-13T20:36:08.425313Z","shell.execute_reply":"2025-05-13T20:36:08.473033Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"mistral = \"mistralai/Mistral-7B-Instruct-v0.3\"\nmistral_model = AutoModelForCausalLM.from_pretrained(\n    mistral,\n    torch_dtype=torch.float16, ## gpu support\n    device_map=None,\n    )\nmistral_tokenizer = AutoTokenizer.from_pretrained(mistral)\nmistral_tokenizer.pad_token = mistral_tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:36:08.475267Z","iopub.execute_input":"2025-05-13T20:36:08.475541Z","iopub.status.idle":"2025-05-13T20:37:25.154618Z","shell.execute_reply.started":"2025-05-13T20:36:08.475512Z","shell.execute_reply":"2025-05-13T20:37:25.154008Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63aa6bf20c934b71811605db9aed98ee"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset\n\ndataset = Dataset.from_dict({\"text\": f})\n\ndef token_func(example):\n    return mistral_tokenizer(\n        example[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n\ntoken_dataset = dataset.map(token_func, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:37:25.155320Z","iopub.execute_input":"2025-05-13T20:37:25.155587Z","iopub.status.idle":"2025-05-13T20:37:27.932393Z","shell.execute_reply.started":"2025-05-13T20:37:25.155562Z","shell.execute_reply":"2025-05-13T20:37:27.931508Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c45506e6e0e4f89ac80988d475bdca9"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=mistral_tokenizer,\n    mlm=False \n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./mistral-continued-pretrain\",\n    overwrite_output_dir=True,\n    num_train_epochs=2,\n    per_device_train_batch_size=1,\n    save_steps=500,\n    save_total_limit=1,\n    prediction_loss_only=True,\n    fp16=True,\n    logging_steps=50,\n)\n\ntrainer = Trainer(\n    model=mistral_model,\n    args=training_args,\n    train_dataset=token_dataset,\n    tokenizer=mistral_tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T20:53:04.620935Z","iopub.execute_input":"2025-05-13T20:53:04.621814Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_474/1571323807.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=mistral_model, tokenizer=mistral_tokenizer)\npipe(\"hello there\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}