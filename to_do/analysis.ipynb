{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0T5_ntBP_tX"
      },
      "outputs": [],
      "source": [
        "# !pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer # model to convert text into code, \"sentence classification\"\n",
        "import numpy as np # store converted text into numbers\n",
        "import pandas as pd # dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-JmL5wFQV_o"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('write_file_here.csv') # can be automatized as well\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnfeMvOiQa-e"
      },
      "outputs": [],
      "source": [
        "## new dataframe to store our data\n",
        "answer_embeddings = df['answer'].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
        "response_embeddings = df['model_response'].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
        "\n",
        "embedding_df = pd.DataFrame({\n",
        "    'answer_embedding': answer_embeddings,\n",
        "    'model_response_embedding': response_embeddings\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_w4GUEOgnrV"
      },
      "outputs": [],
      "source": [
        "## COSINE SIMMULARITY\n",
        "\n",
        "import torch # pytorch\n",
        "\n",
        "answers = torch.stack(embedding_df['answer_embedding'].tolist())          # 768\n",
        "responses = torch.stack(embedding_df['model_response_embedding'].tolist()) # 768\n",
        "\n",
        "cos_sim = torch.nn.functional.cosine_similarity(answers, responses, dim=1)\n",
        "\n",
        "embedding_df['cosine_similarity'] = cos_sim.tolist()\n",
        "\n",
        "print(\"cosine similarity:\", cos_sim.mean().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hsz2dFfhBv9"
      },
      "outputs": [],
      "source": [
        "## BERTScore\n",
        "!pip install bert_score\n",
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(df['answer'].tolist(), df['model_response'].tolist(), lang='en')\n",
        "print(f\"BERTScore F1: {F1.mean().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJy7WQW_jRYf"
      },
      "outputs": [],
      "source": [
        "### comparison (predefined manually for now, can be automatized)\n",
        "comparison = pd.DataFrame([\n",
        "    {\n",
        "        \"model\": \"falcon\",\n",
        "        \"bert_score\": 0.8710,\n",
        "        \"cosine_similarity\": 0.6338\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"phi\",\n",
        "        \"bert_score\": 0.8722,\n",
        "        \"cosine_similarity\": 0.6522\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"tiny-llama\",\n",
        "        \"bert_score\": 0.8835,\n",
        "        \"cosine_similarity\": 0.7044\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"llama-regular\",\n",
        "        \"bert_score\": 0.8609,\n",
        "        \"cosine_similarity\": 0.6323\n",
        "    }\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "uPt3lXzTlIet",
        "outputId": "92eb3638-617b-4eee-ab95-cd013ff7be39"
      },
      "outputs": [],
      "source": [
        "### vizualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# bert\n",
        "axs[0].bar(comparison['model'], comparison['bert_score'], color='skyblue')\n",
        "axs[0].set_title('BERTScore')\n",
        "axs[0].set_ylim(0.85, 0.89)\n",
        "axs[0].set_ylabel('BERTScore')\n",
        "\n",
        "# cosines\n",
        "axs[1].bar(comparison['model'], comparison['cosine_similarity'], color='lightcoral')\n",
        "axs[1].set_title('Cosine Similarity')\n",
        "axs[1].set_ylim(0.6, 0.72)\n",
        "axs[1].set_ylabel('Similarity')\n",
        "\n",
        "# to show\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hlTTFbZ5khM"
      },
      "outputs": [],
      "source": [
        "### Training loss visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 500 steps cap\n",
        "steps = [\n",
        "    20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 300,\n",
        "    320, 340, 360, 380, 400, 420, 440, 460, 480, 500\n",
        "]\n",
        "\n",
        "deepseek_training_loss = [\n",
        "    2.765200, 2.728700, 2.743500, 2.719200, 2.689300, 2.666000, 2.637700, 2.610000,\n",
        "    2.558400, 2.548900, 2.512600, 2.502900, 2.473300, 2.434500, 2.391300, 2.365100,\n",
        "    2.337500, 2.292600, 2.257300, 2.223900, 2.198400, 2.147000, 2.112200, 2.073000,\n",
        "    2.051100\n",
        "]\n",
        "\n",
        "mistral_training_loss = [\n",
        "    2.476000, 2.366600, 2.306900, 2.223500, 2.149900,\n",
        "    2.073800, 2.005600, 1.935900, 1.866000, 1.818300,\n",
        "    1.741800, 1.688900, 1.635900, 1.565200, 1.510900,\n",
        "    1.459100, 1.412600, 1.371500, 1.315800, 1.292200,\n",
        "    1.274700, 1.231600, 1.213700, 1.197200, 1.193000\n",
        "]\n",
        "\n",
        "llama_training_loss = [\n",
        "    2.7158, 2.6620, 2.6716, 2.6292, 2.5907,\n",
        "    2.5482, 2.5087, 2.4656, 2.4141, 2.3933,\n",
        "    2.3407, 2.3150, 2.2749, 2.2214, 2.1656,\n",
        "    2.1259, 2.0871, 2.0329, 1.9817, 1.9444,\n",
        "    1.9051, 1.8472, 1.7964, 1.7537, 1.7201\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(steps, deepseek_training_loss, marker='o', linestyle='-', color='blue')\n",
        "plt.plot(steps, mistral_training_loss, marker='o', linestyle='-', color='red')\n",
        "plt.plot(steps, llama_training_loss, marker='o', linestyle='-', color='black')\n",
        "plt.title('Training Loss over Steps')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPhuUudq9PQElueSTRFmg9V",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
