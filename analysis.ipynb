{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK+gPn/PdjrwG+WuTZwEW5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0T5_ntBP_tX"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer # model to convert text into code, \"sentence classification\"\n",
        "import numpy as np # store converted text into numbers\n",
        "import pandas as pd # dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./falcon_results (2).csv')\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "## new dataframe to store our data\n",
        "answer_embeddings = df['answer'].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
        "response_embeddings = df['model_response'].apply(lambda x: model.encode(x, convert_to_tensor=True))\n",
        "\n",
        "embedding_df = pd.DataFrame({\n",
        "    'answer_embedding': answer_embeddings,\n",
        "    'model_response_embedding': response_embeddings\n",
        "})"
      ],
      "metadata": {
        "id": "t-JmL5wFQV_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_df"
      ],
      "metadata": {
        "id": "DnfeMvOiQa-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## COSINE SIMMULARITY\n",
        "\n",
        "import torch # pytorch\n",
        "\n",
        "answers = torch.stack(embedding_df['answer_embedding'].tolist())          # 768\n",
        "responses = torch.stack(embedding_df['model_response_embedding'].tolist()) # 768\n",
        "\n",
        "cos_sim = torch.nn.functional.cosine_similarity(answers, responses, dim=1)\n",
        "\n",
        "embedding_df['cosine_similarity'] = cos_sim.tolist()\n",
        "\n",
        "print(\"cosine similarity:\", cos_sim.mean().item())"
      ],
      "metadata": {
        "id": "P_w4GUEOgnrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## BERTScore\n",
        "!pip install bert_score\n",
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(df['answer'].tolist(), df['model_response'].tolist(), lang='en')\n",
        "print(f\"BERTScore F1: {F1.mean().item():.2f}\")"
      ],
      "metadata": {
        "id": "5Hsz2dFfhBv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJy7WQW_jRYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}